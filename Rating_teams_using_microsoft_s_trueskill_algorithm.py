# -*- coding: utf-8 -*-
"""Copy of rating-teams-using-microsoft-s-trueskill-algorithm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UiDCE1c90ciS657jC1coH1lTo59OFNGC

Microsoft has created an algorithm called *TrueSkill* for the purpose of ranking players using its video game platform.  It is basically a probabalistic algorithm based on the *Elo* algorithm used to rank chess players.  It can be used to rank players in any activity where there is some concept of win/lose/draw.  The algorithm itself is somewhat hard to understand but fortunately someone has created a Python package which makes it easy to use without understanding the theory behind it.

First we read in the data files we need.
"""

import pandas as pd 

#season_data = pd.read_csv('RegularSeasonDetailedResults.csv')
tourney_data = pd.read_csv('NCAATourneyDetailedResults.csv')
results = pd.read_csv('RegularSeasonDetailedResults.csv')
#tourney = pd.read_csv('NCAATourneyCompactResults.csv')
seeds = pd.read_csv('NCAATourneySeeds.csv')
teams = pd.read_csv('Teams.csv')
frames = [results, tourney_data]
all_data = pd.concat(frames)
stat_fields = [
    # offensive statistics
    'fgm',              # field goal made
    'fga',              # field goal attempted
    'fgp',              # field goal percentage
    'fgm3',             # 3pt field goal made
    'fga3',             # 3 points field goal attempted
    '3pp',              # 3 points field goal percentage
    'ftm',              # free throw made
    'fta',              # free throw attempted
    'ftp',              # free throw percentage
    'ef_fg_perc',       # effective field goal percentage
    'f_throw_factor',   # free throw factor
    # defensive statistics
    'totalreb_perc',    # total rebound percentage
    'or',               # offensive rebound
    'offreb_perc',      # offensive rebound percentage
    'dr',               # defensive rebound
    'defreb_perc',      # defensive rebound percentage
    'to',               # turnover
    'ast',              # assist
    'ast_ratio',        # assist ratio 
    'to_ratio',         # turnover ratio
    'to_factor',        # turnover factor both defense & offense
    'stl',              # steal
    'blk',              # block
    'pf',               # personal foul
    ]
all_data.head(12)

!pip install trueskill

"""Next we define the function which actually uses TrueSkill to rank the teams in a given season."""

#!pip install trueskill
from trueskill import Rating, rate_1vs1
from collections import defaultdict

def get_ratings(season):         
    # start all teams with a default rating
    ratings = defaultdict(Rating)         
    # get data for season
    current_results = results[results['Season'] == season]                                           
    # at the start, all teams are equal which is not realistic so we loop
    # through the season's games several times to get better starting ratings
    for epoch in range(10):                                 
        # loop through the games in order
        for _, row in current_results.sort_values('DayNum').iterrows():                                                    
            wteamid = row['WTeamID']                                                                 
            lteamid = row['LTeamID']    
            # have TrueSkill compute new ratings based on the game result
            ratings[wteamid], ratings[lteamid] = rate_1vs1(ratings[wteamid], ratings[lteamid])       
    # just keep the mean rating
    return {team_id: rating.mu for team_id, rating in ratings.items()}

prediction_year = 2019
team_stats = {}
X = []
y = []
submission_data = []
def initialize_data():
    for i in range(1985, prediction_year+1):
        #ratings[i] = {}
        team_stats[i] = {}
initialize_data()

def get_stat(season, team, field):
  try:
    l = team_stats[season][team][field]
    return sum(l) / float(len(l))
  except:
    return 0


def update_stats(season, team, fields):
  if team not in team_stats[season]:
    team_stats[season][team] = {}
    for key, value in fields.items():
      # Make sure we have the field.
      if key not in team_stats[season][team]:
        team_stats[season][team][key] = []
        if len(team_stats[season][team][key]) >= 9:
          team_stats[season][team][key].pop()
          team_stats[season][team][key].append(value)    

def predict_winner(team_1, team_2, model, season, stat_fields):
  features = []
  # Team 1
  features.append(get_ratings(season, team_1))
  for stat in stat_fields:
    features.append(get_stat(season, team_1, stat))
  # Team 2
  features.append(get_ratings(season, team_2))
  for stat in stat_fields:
    features.append(get_stat(season, team_2, stat))
  #return model.predict_proba([features]).clip(0.025, 0.975)
  return model.predict_proba([features])

# Step 5: Feature Selection and Feature Engineering
## Our classifier will make its decision based off of the values for 25 features. One important feature is 
## a ranking metric called ratings while the remaining 24 features are traditional basketball metrics as described below:

### Features
"""
	wfgm: field goals made
	wfga: field goals attempted
	wfgm3: three pointers made
	wfga3: three pointers attempted
	wftm: free throws made
	wfta: free throws attempted
	wor: offensive rebounds
	wdr: defensive rebounds
	wast: assists
	wto: turnovers
	wstl: steals
	wblk: blocks
	wpf: personal fouls
"""
### Engineered Features
"""
    fgp: field goal percentage
    3pp: three point percentage
    ftp: free throw percentage
    ef_fg_perc: Effective Field Goal Percentage
    f_throw_factor: Free throw Factor
    totalreb_perc: Total Rebound Percentage	
    offreb_perc: Offensive Rebound Percentage    
    defreb_perc: Defensive Rebound Percentage
    ast_ratio: Assist Ratio
    to_ratio: Turnover Ratio    
    to_factor: Turnover Factor
"""
def build_season_data(all_data):
  # Calculate the ranking for every game for every team, each season.
  # Store the ratings per season so we can retrieve their end ratings
  # later in order to predict the tournaments without having to inject the prediction into this loop.
  for index, row in all_data.iterrows():
    # Used to skip matchups where we don't have usable stats yet.
    skip = 0
    # Get starter or previous ratings.
    team_1_ratings = get_ratings(row['Season'], row['WTeamID'])
    team_2_ratings = get_ratings(row['Season'], row['LTeamID'])
    # Add 100 to the home team (# taken from Nate Silver analysis.)
    #if row['WLoc'] == 'H':
     # team_1_ratings += 100
    #elif row['WLoc'] == 'A':
    #  team_2_ratings += 100
    # We'll create some arrays to use later.
    team_1_features = [team_1_ratings]
    team_2_features = [team_2_ratings]
    # Build arrays out of the stats we're tracking..
    for field in stat_fields:
      team_1_stat = get_stat(row['Season'], row['WTeamID'], field)
      team_2_stat = get_stat(row['Season'], row['LTeamID'], field)
      if team_1_stat is not 0 and team_2_stat is not 0:
        team_1_features.append(team_1_stat)
        team_2_features.append(team_2_stat)
      else:
        skip = 1
    if skip == 0:  # Make sure we have stats.
      # Randomly select left and right and 0 or 1 so we can train
      # for multiple classes.
      if random.random() > 0.5:
        X.append(team_1_features + team_2_features)
        y.append(0)
      else:
        X.append(team_2_features + team_1_features)
        y.append(1)
        # AFTER we add the current stuff to the prediction, update for
        # next time. Order here is key so we don't fit on data from the
        # same game we're trying to predict.
    if row['WFTA'] != 0 and row['LFTA'] != 0:
      stat_1_fields = {
          # offense statistics
          'fgm': row['WFGM'],
          'fga': row['WFGA'],
          'fgp': (row['WFGM'] / row['WFGA']) * 100,
          'fgm3': row['WFGM3'],
          'fga3': row['WFGA3'],
          '3pp': (row['WFGM3'] / row['WFGA3']) * 100,
          'ftm': row['WFTM'],
          'fta': row['WFTA'],
          'ftp': (row['WFTM'] / row['WFTA']) * 100,
          'ef_fg_perc': 100 * (row['WFGM'] + (0.5 * row['WFGM3'])) / row['WFGA'],
          'f_throw_factor': (row['WFTM'] / row['WFGM']) / (row['WFTA'] / row['WFGA']),
          # defense statistics
          'totalreb_perc': (row['WDR'] + row['WOR']) / (row['WDR'] + row['WOR'] + row['LDR'] + row['LOR']),
          'or': row['WOR'],
          'offreb_perc': 100 * (row['WOR'] / (row['WOR'] + row['LDR'])),
          'dr': row['WDR'],
          'defreb_perc': 100 * (row['WDR'] / (row['WDR'] + row['LOR'])),
          'to': row['WTO'],
          'ast': row['WAst'],
          'ast_ratio': 100 * (row['WAst'] / row['WFGA'] + (0.475 * row['WFTA']) + row['WAst'] + row['WTO']),
          'to_ratio': 100 * (row['WTO'] / row['WFGA'] + (0.475 * row['WFTA']) + row['WAst'] + row['WTO']),
          'to_factor': row['WTO'] / (row['WFGA'] + (0.475 * row['WFTA']) + row['WTO']),
          'stl': row['WStl'],
          'blk': row['WBlk'],
          'pf': row['WPF'],
      }
      
      stat_2_fields = {
          # offense statistics
          'fgm': row['LFGM'],
          'fga': row['LFGA'],
          'fgp': (row['LFGM'] / row['LFGA']) * 100,
          'fgm3': row['LFGM3'],
          'fga3': row['LFGA3'],
          '3pp': (row['LFGM3'] / row['LFGA3']) * 100,
          'ftm': row['LFTM'],
          'fta': row['LFTA'],
          'ftp': row['LFTM'] / row['LFTA'] * 100,
          'ef_fg_perc': 100 * (row['LFGM'] + (0.5 * row['LFGM3'])) / row['LFGA'],
          'f_throw_factor': (row['LFTM'] / row['LFGM']) / (row['LFTA'] / row['LFGA']),
          # defense statistics
          'totalreb_perc': (row['LDR'] + row['LOR']) / (row['WDR'] + row['WOR'] + row['LDR'] + row['LOR']),
          'or': row['LOR'],
          'offreb_perc': 100 * (row['LOR'] / (row['LOR'] + row['WDR'])),
          'dr': row['LDR'],
          'defreb_perc': 100 * (row['LDR'] / (row['LDR'] + row['WOR'])),
          'to': row['LTO'],
          'ast': row['LAst'],
          'ast_ratio': 100 * (row['LAst'] / row['LFGA'] + (0.475 * row['LFTA']) + row['LAst'] + row['LTO']),
          'to_ratio': 100 * (row['LTO'] / row['LFGA'] + (0.475 * row['LFTA']) + row['LAst'] + row['LTO']),
          'to_factor': row['LTO'] / (row['LFGA'] + (0.475 * row['LFTA']) + row['LTO']),
          'stl': row['LStl'],
          'blk': row['LBlk'],
          'pf': row['LPF'],
      }
      update_stats(row['Season'], row['WTeamID'], stat_1_fields)
      update_stats(row['Season'], row['LTeamID'], stat_2_fields)
    # Now that we've added them, calc the new ratings.
    new_winner_rank, new_loser_rank = Rating(
        row['WTeamID'], row['LTeamID'])
    ratings[row['Season']][row['WTeamID']] = new_winner_rank
    ratings[row['Season']][row['LTeamID']] = new_loser_rank
  return X, y
X, y = build_season_data(all_data)

"""The above function is a bit slow, so we'll use multiprocessing to compute ratings for each season in parallel."""

from multiprocessing import Pool

p = Pool()    
seasons = results['Season'].unique()
ratings = p.map(get_ratings, seasons)                                                                
p.close()                                                                                            
p.join() 

# put ratings into a dict for easy access
ratings = dict(zip(seasons, ratings, team))

# lets take a look at 2019 rankings
team_names = dict(zip(teams['TeamID'], teams['TeamName']))
ratings_2019 = [(team_names[t], r) for t, r in ratings[2018].items()]
pd.DataFrame(ratings_2019, columns=['TeamID', 'Rating']).sort_values('Rating', ascending=False)

"""So now that we have ratings we can try to turn them into probabilities for the 2019 tournament games.  We will do this by using results from past NCAA tournament games with the ratings as features and training a logistic regression model."""

train = []                                                                                           
target = []              
# create training data with past tournament results
for _, row in tourney.iterrows():                                                                    
    season = row['Season']                                                                           
    wteamid = row['WTeamID']                                                                         
    lteamid = row['LTeamID']                                                                         
    # we add two rows per game so the target is not all '0' or '1'
    # it might be better to randomly choose winner or loser first
    # or always have higher ratings first
    train.append([ratings[season][wteamid], ratings[season][lteamid]])                               
    target.append(1)                                                                                 
    train.append([ratings[season][lteamid], ratings[season][wteamid]])                               
    target.append(0)     
train = pd.DataFrame(train, columns=['Team1', 'Team2'])
target = pd.Series(target, name='Target')
pd.concat((train, target), axis=1)

"""OK, now we can train a model to give winning probability given two ratings."""

from sklearn.linear_model import LogisticRegression                                                  
from sklearn.preprocessing import StandardScaler 

ss = StandardScaler()                                                                                                                                
train = ss.fit_transform(train)                                                            
lr = LogisticRegression()                                                                            
lr.fit(train, target) 
'intercept: {} coefficients: {}'.format(lr.intercept_[0], lr.coef_[0])

"""Now that we have our model, we can predict winning probabilities for 2019 tournament games.  First we need to build a test set similar to the training set."""

# get seeds for 2019 tournament
seeds2019 = seeds['TeamID'][seeds['Season'] == 2019].unique() 
# loop though every possible matchup
predictions = []
for team1 in seeds2019:                                                                                  
    for team2 in seeds2019:                                                                              
        if team1 < team2:
            # we're going to get probabilites for team1 vs team2 and team2 vs team1 and average them
            test_rows = [                                                                            
                [ratings[2019][team1], ratings[2019][team2]],                                        
                [ratings[2019][team2], ratings[2019][team1]],                                        
            ]                                                                                        
            test_rows = ss.transform(test_rows)                                                      
            prob = lr.predict_proba(test_rows)[:, 1]                                                 
            avg_prob = (prob[0] + (1 - prob[1])) / 2     
            predictions.append([team_names[team1], team_names[team2], avg_prob])

"""Any now we can look at the results."""

pd.DataFrame(predictions, columns=['Team1', 'Team2', 'Team1 Win Prob'])

#ratings
predictions

from sklearn.metrics import log_loss

log_loss(target, predictions, eps=1e-15)